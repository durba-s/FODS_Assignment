{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f88f39",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6faf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024580e6",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92f2e958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>1060</td>\n",
       "      <td>1540</td>\n",
       "      <td>7420</td>\n",
       "      <td>453000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>9861</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2390</td>\n",
       "      <td>9761</td>\n",
       "      <td>480000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>9800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>530</td>\n",
       "      <td>1600</td>\n",
       "      <td>8250</td>\n",
       "      <td>180500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2380.0</td>\n",
       "      <td>6250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>710</td>\n",
       "      <td>2540</td>\n",
       "      <td>4010</td>\n",
       "      <td>495000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>8500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2270</td>\n",
       "      <td>8770</td>\n",
       "      <td>325000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
       "0         4       1.75       2120.0      7420     1.0           0     0   \n",
       "1         4       2.50       2180.0      9861     2.0           0     2   \n",
       "2         3       1.50       1540.0      9800     1.0           0     0   \n",
       "3         3       3.50       2380.0      6250     2.0           0     3   \n",
       "4         4       2.50       2230.0      8500     2.0           0     0   \n",
       "\n",
       "   condition  grade  sqft_above  sqft_basement  sqft_living15  sqft_lot15  \\\n",
       "0          4      7      1060.0           1060           1540        7420   \n",
       "1          3      8      2180.0              0           2390        9761   \n",
       "2          3      7      1010.0            530           1600        8250   \n",
       "3          3      8      1670.0            710           2540        4010   \n",
       "4          3      8      2230.0              0           2270        8770   \n",
       "\n",
       "      price  \n",
       "0  453000.0  \n",
       "1  480000.0  \n",
       "2  180500.0  \n",
       "3  495000.0  \n",
       "4  325000.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn=\"./FoDS-Assignment-2.csv\"\n",
    "df=pd.read_csv(fn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff7885",
   "metadata": {},
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee45f4",
   "metadata": {},
   "source": [
    "#### Dataframe Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277300ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45600c6",
   "metadata": {},
   "source": [
    "#### Number of Duplicate data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e40834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaf0eb",
   "metadata": {},
   "source": [
    "#### Number of unique values and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0bc08d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ud=[]\n",
    "nd=[]\n",
    "for col in df.columns:\n",
    "    ud.append(len(pd.unique(df[col])))\n",
    "    nd.append(df[col].isnull().sum())\n",
    "df_s={'Feature Number': [0,1,2,3,4,5,6,7,8,9,10,11,12,'Target Attribute'],'Feature Name':df.columns,\n",
    "        'Number of Unique Values':ud,\n",
    "     'Number of Null Values':nd}\n",
    "df_s=pd.DataFrame(df_s)\n",
    "df_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1c2f1",
   "metadata": {},
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c5c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(data = df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca825084",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296198c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(15, 50))\n",
    "i=1\n",
    "for s in df.columns:\n",
    "    plt.subplot(7,4, i)\n",
    "    plt.title(s)\n",
    "    plt.grid()\n",
    "    sns.boxplot(data=df[[s]])\n",
    "    i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6198b",
   "metadata": {},
   "source": [
    "#### Scatter Plots (Individual Features VS Target Attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3cde9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,40))\n",
    "plt.rc('axes', labelsize=25)\n",
    "for i, col in enumerate(df.columns[:-1]):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.scatter(df[col], df[\"price\"])\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866fb65",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e8317d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "  def __init__(self,X):\n",
    "    self.X = np.array(X)\n",
    "\n",
    "  def outlier_indices(self, k, threshold):   \n",
    "    dist = []\n",
    "    for i in range(0,self.X.shape[0]):\n",
    "      distance = np.linalg.norm(self.X - self.X[i, :], axis = 1)\n",
    "      distance[i] = np.Infinity\n",
    "      dist.append(np.mean(distance[np.argsort(distance)[:k]]))\n",
    "    return np.squeeze(np.argwhere(np.array(dist) >= threshold)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "faf027a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers = 138\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 0.25295462994340945\n",
      "Val MSE 0.1799868626247549\n",
      "Test MSE 0.1787476246184193\n"
     ]
    }
   ],
   "source": [
    "def preprocess(data,f=0.6,scalingMethod=\"standardize\", outlierMethod=\"knn\", knn_k=5, knn_threshold=2, tstd_threshold=2.5, missingValues=\"drop\"):\n",
    "    EPS = 1e-12\n",
    "\n",
    "    if missingValues == \"drop\":\n",
    "        data = data.dropna()\n",
    "    elif missingValues == \"imputemean\":\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].fillna((data[col].mean()))\n",
    "    \n",
    "    if outlierMethod == \"knn\":\n",
    "        scaled_data = data.iloc[:,:-1]\n",
    "        scaled_data = (scaled_data - scaled_data.mean())/scaled_data.std()\n",
    "        knn = KNN(scaled_data)\n",
    "        outlier_index = knn.outlier_indices(knn_k, knn_threshold)\n",
    "        print(f\"Number of outliers = {len(outlier_index)}\")\n",
    "        data = data.drop(data.index[outlier_index])\n",
    "    elif outlierMethod == \"tstd\":\n",
    "        target = data.iloc[:,-1]\n",
    "        target = (target - target.mean())/target.std()\n",
    "        outlier_index = np.argwhere(target >= tstd_threshold)\n",
    "        data = data.drop(data.index[outlier_index])\n",
    "\n",
    "    #train test split\n",
    "    train = data.sample(frac=f, random_state=0)\n",
    "    val_data = data.drop(train.index)\n",
    "    val = val_data.sample(frac=0.5, random_state=1)\n",
    "    test = val_data.drop(val.index)    \n",
    "    X_train = train.iloc[:, :-1]\n",
    "    y_train = train.iloc[:, -1]\n",
    "    X_val = val.iloc[:,:-1]\n",
    "    y_val = val.iloc[:, -1]\n",
    "    X_test = test.iloc[:, :-1]\n",
    "    y_test = test.iloc[:, -1]\n",
    "    \n",
    "    if scalingMethod == None:\n",
    "        return np.array(X_train), np.array(y_train).reshape(-1,1), np.array(X_val), np.array(y_val).reshape(-1,1), np.array(X_test), np.array(y_test).reshape(-1,1), 0, 1, 0, 1\n",
    "    elif scalingMethod == \"standardize\":\n",
    "        Xmean = X_train.mean()\n",
    "        Xsd = X_train.std()\n",
    "        ymean = y_train.mean()\n",
    "        ysd = y_train.std()\n",
    "        X_train = (X_train - Xmean) / (Xsd + EPS)\n",
    "        X_val = (X_val - Xmean) / (Xsd + EPS)\n",
    "        X_test = (X_test - Xmean) / (Xsd + EPS)\n",
    "        y_train = (y_train - ymean) / (ysd + EPS)\n",
    "        y_val = (y_val - ymean) / (ysd + EPS)\n",
    "        y_test = (y_test - ymean) / (ysd + EPS)\n",
    "        return np.array(X_train), np.array(y_train).reshape(-1,1), np.array(X_val), np.array(y_val).reshape(-1,1), np.array(X_test), np.array(y_test).reshape(-1,1), Xmean, Xsd, ymean, ysd\n",
    "    elif scalingMethod == \"scale\":\n",
    "        Xminval = X_train.min()\n",
    "        Xdiff = X_train.max() - X_train.min()\n",
    "        yminval = y_train.min()\n",
    "        ydiff = y_train.max() - y_train.min()\n",
    "        X_train = (X_train - Xminval) / (Xdiff + EPS)\n",
    "        X_val = (X_train - Xminval) / (Xdiff + EPS)\n",
    "        X_test = (X_test - Xminval) / (Xdiff + EPS)\n",
    "        y_train = (y_train - yminval) / (ydiff + EPS)\n",
    "        y_val = (y_val - yminval) / (ydiff + EPS)\n",
    "        y_test = (y_test - yminval) / (ydiff + EPS)\n",
    "        return np.array(X_train), np.array(y_train).reshape(-1,1), np.array(X_val), np.array(y_val).reshape(-1,1), np.array(X_test), np.array(y_test).reshape(-1,1), Xminval, Xdiff, yminval, ydiff\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, xnum, xdr, ynum, ydr = preprocess(df)\n",
    "model = LinearRegression(X_train, y_train)\n",
    "W,b = model.fitGD(lr=0.01, graph=True)\n",
    "print('Train MSE',model.MSE(y_train, model.predict(X_train)))\n",
    "print('Val MSE',model.MSE(y_val, model.predict(X_val)))\n",
    "print('Test MSE',model.MSE(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e386526",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bce0928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "            self.X = X #(n,d)\n",
    "            self.y = y #(n,1)\n",
    "            self.W = np.zeros((1, X.shape[1])) #(1,d)\n",
    "            self.b = 1\n",
    "\n",
    "    def fitGD(self, n_iter=1000, lr=0.01, graph=False):\n",
    "        mse = []\n",
    "        for i in range(n_iter):\n",
    "            yp = self.predict(self.X)\n",
    "            mse.append(self.MSE(self.y, yp))\n",
    "            Wgrad = (1/self.X.shape[0])*((self.X.T)@(yp-self.y)).T #(d,n)*(n,1) = (d,1)\n",
    "            self.W = self.W - lr * Wgrad\n",
    "            self.b = self.b - lr * np.mean(yp-self.y)\n",
    "        if(graph == True):\n",
    "            plt.plot(mse)\n",
    "            plt.show()\n",
    "        return self.W, self.b\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (X@self.W.T + self.b)\n",
    "\n",
    "    def MSE(self, y, yp):\n",
    "        return 0.5*np.mean((y-yp)**2)\n",
    "    \n",
    "    def RMSE(self, y, yp):\n",
    "        return np.sqrt(self.MSE(y, yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52cfda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9516fcc7",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "26b1c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GFFS(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    d = X_train.shape[1]\n",
    "    remaining = list(range(d))\n",
    "    selected = []\n",
    "    train_MSE = []\n",
    "    val_MSE = []\n",
    "    test_MSE = []\n",
    "    for i in range(d):\n",
    "        print(i+1)\n",
    "        min_mse = 1e100\n",
    "        min_mse_val = 1e100\n",
    "        min_mse_test = 1e100\n",
    "        min_j = -1\n",
    "        for j in remaining:\n",
    "            cur_features = selected + [j]\n",
    "            X_train_cur = X_train[:,cur_features]\n",
    "            X_val_cur = X_val[:, cur_features]\n",
    "            X_test_cur = X_test[:, cur_features]\n",
    "            model = LinearRegression(X_train_cur, y_train)\n",
    "            model.fitGD(lr=0.01,n_iter=1000)\n",
    "            mse = model.MSE(y_train,model.predict(X_train_cur))\n",
    "            mse_val = model.MSE(y_val,model.predict(X_val_cur))\n",
    "            mse_test = model.MSE(y_test,model.predict(X_test_cur))\n",
    "            if mse_val < min_mse_val:\n",
    "                min_mse = mse\n",
    "                min_mse_val = mse_val\n",
    "                min_mse_test = mse_test\n",
    "                min_j = j\n",
    "        train_MSE.append(min_mse)\n",
    "        val_MSE.append(min_mse_val)\n",
    "        test_MSE.append(min_mse_test)\n",
    "        selected.append(min_j)\n",
    "        remaining.remove(min_j)\n",
    "        print(min_mse,selected)\n",
    "    return selected, train_MSE, val_MSE, test_MSE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f250a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBFS(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    d = X_train.shape[1]\n",
    "    removed = [-1]\n",
    "    selected = list(range(d))\n",
    "    model = LinearRegression(X_train, y_train)\n",
    "    model.fitGD(lr=0.01,n_iter=10000)\n",
    "    train_MSE = [model.MSE(y_train, model.predict(X_train))]\n",
    "    val_MSE = [model.MSE(y_val, model.predict(X_val))]\n",
    "    test_MSE = [model.MSE(y_test, model.predict(X_test))]\n",
    "    for i in range(d-1):\n",
    "        print(d-i)\n",
    "        min_mse = 1e100\n",
    "        min_mse_val = 1e100\n",
    "        min_mse_test = 1e100\n",
    "        min_j = -1\n",
    "        for j in selected:\n",
    "            cur_features = [x for x in selected if x != j]\n",
    "            X_train_cur = X_train[:, cur_features]\n",
    "            X_val_cur = X_val[:, cur_features]\n",
    "            X_test_cur = X_test[:, cur_features]\n",
    "            model = LinearRegression(X_train_cur, y_train)\n",
    "            model.fitGD(lr=0.01,n_iter=1000)\n",
    "            mse = model.MSE(y_train,model.predict(X_train_cur))\n",
    "            mse_val = model.MSE(y_val,model.predict(X_val_cur))\n",
    "            mse_test = model.MSE(y_test,model.predict(X_test_cur))\n",
    "            if mse_val < min_mse_val:\n",
    "                min_mse = mse\n",
    "                min_mse_val = mse_val\n",
    "                min_mse_test = mse_test\n",
    "                min_j = j\n",
    "        train_MSE.append(min_mse)\n",
    "        val_MSE.append(min_mse_val)\n",
    "        test_MSE.append(min_mse_test)\n",
    "        selected.remove(min_j)\n",
    "        removed.append(min_j)\n",
    "        print(min_mse, selected)\n",
    "    removed.append(selected[0])\n",
    "    return removed, train_MSE, val_MSE, test_MSE    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f21f61",
   "metadata": {},
   "source": [
    "## Eval Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c356be",
   "metadata": {},
   "source": [
    "### Linear regression model without any pre-processing and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7bd62f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers = 138\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 0.25295462994340945\n",
      "Val MSE 0.1799868626247549\n",
      "Test MSE 0.1787476246184193\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, xnum, xdr, ynum, ydr = preprocess(df)\n",
    "model = LinearRegression(X_train, y_train)\n",
    "W,b = model.fitGD(lr=0.01, graph=True)\n",
    "print('Train MSE',model.MSE(y_train, model.predict(X_train)))\n",
    "print('Val MSE',model.MSE(y_val, model.predict(X_val)))\n",
    "print('Test MSE',model.MSE(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51954b3",
   "metadata": {},
   "source": [
    "### Greedy forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c9758476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers = 138\n",
      "1\n",
      "0.32401005490881585 [2]\n",
      "2\n",
      "0.28015145165098954 [2, 8]\n",
      "3\n",
      "0.2787323076332088 [2, 8, 10]\n",
      "4\n",
      "0.2775148926404484 [2, 8, 10, 3]\n",
      "5\n",
      "0.27413954394605156 [2, 8, 10, 3, 11]\n",
      "6\n",
      "0.26759699182156077 [2, 8, 10, 3, 11, 7]\n",
      "7\n",
      "0.26613614274255987 [2, 8, 10, 3, 11, 7, 0]\n",
      "8\n",
      "0.26613614274255987 [2, 8, 10, 3, 11, 7, 0, 5]\n",
      "9\n",
      "0.26614385303183646 [2, 8, 10, 3, 11, 7, 0, 5, 12]\n",
      "10\n",
      "0.2644088367410126 [2, 8, 10, 3, 11, 7, 0, 5, 12, 1]\n",
      "11\n",
      "0.2642581281393565 [2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4]\n",
      "12\n",
      "0.2639836905715301 [2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4, 9]\n",
      "13\n",
      "0.25295462994340945 [2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4, 9, 6]\n",
      "[2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4, 9, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sqft_living', 'grade', 'sqft_basement', 'sqft_lot',\n",
       "       'sqft_living15', 'condition', 'bedrooms', 'waterfront',\n",
       "       'sqft_lot15', 'bathrooms', 'floors', 'sqft_above', 'view'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, xnum, xdr, ynum, ydr = preprocess(df)\n",
    "selected, GFFS_MSE_train, GFFS_MSE_val, GFFS_MSE_test = GFFS(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "print(selected)\n",
    "np.array(df.columns)[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "585559b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Subsets (GFFS)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>Feature Subset</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Val MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.324010</td>\n",
       "      <td>0.193892</td>\n",
       "      <td>0.198382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[2, 8]</td>\n",
       "      <td>0.280151</td>\n",
       "      <td>0.186149</td>\n",
       "      <td>0.201409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 8, 10]</td>\n",
       "      <td>0.278732</td>\n",
       "      <td>0.179573</td>\n",
       "      <td>0.196570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 8, 10, 3]</td>\n",
       "      <td>0.277515</td>\n",
       "      <td>0.175606</td>\n",
       "      <td>0.195076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[2, 8, 10, 3, 11]</td>\n",
       "      <td>0.274140</td>\n",
       "      <td>0.173493</td>\n",
       "      <td>0.192623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[2, 8, 10, 3, 11, 7]</td>\n",
       "      <td>0.267597</td>\n",
       "      <td>0.172117</td>\n",
       "      <td>0.185882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[2, 8, 10, 3, 11, 7, 0]</td>\n",
       "      <td>0.266136</td>\n",
       "      <td>0.172016</td>\n",
       "      <td>0.189306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[2, 8, 10, 3, 11, 7, 0, 5]</td>\n",
       "      <td>0.266136</td>\n",
       "      <td>0.172016</td>\n",
       "      <td>0.189306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[2, 8, 10, 3, 11, 7, 0, 5, 12]</td>\n",
       "      <td>0.266144</td>\n",
       "      <td>0.172079</td>\n",
       "      <td>0.189270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[2, 8, 10, 3, 11, 7, 0, 5, 12, 1]</td>\n",
       "      <td>0.264409</td>\n",
       "      <td>0.172239</td>\n",
       "      <td>0.190729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4]</td>\n",
       "      <td>0.264258</td>\n",
       "      <td>0.173703</td>\n",
       "      <td>0.190242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4, 9]</td>\n",
       "      <td>0.263984</td>\n",
       "      <td>0.175880</td>\n",
       "      <td>0.189642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4, 9, 6]</td>\n",
       "      <td>0.252955</td>\n",
       "      <td>0.179987</td>\n",
       "      <td>0.178748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     d                              Feature Subset  Train MSE   Val MSE  \\\n",
       "0    1                                         [2]   0.324010  0.193892   \n",
       "1    2                                      [2, 8]   0.280151  0.186149   \n",
       "2    3                                  [2, 8, 10]   0.278732  0.179573   \n",
       "3    4                               [2, 8, 10, 3]   0.277515  0.175606   \n",
       "4    5                           [2, 8, 10, 3, 11]   0.274140  0.173493   \n",
       "5    6                        [2, 8, 10, 3, 11, 7]   0.267597  0.172117   \n",
       "6    7                     [2, 8, 10, 3, 11, 7, 0]   0.266136  0.172016   \n",
       "7    8                  [2, 8, 10, 3, 11, 7, 0, 5]   0.266136  0.172016   \n",
       "8    9              [2, 8, 10, 3, 11, 7, 0, 5, 12]   0.266144  0.172079   \n",
       "9   10           [2, 8, 10, 3, 11, 7, 0, 5, 12, 1]   0.264409  0.172239   \n",
       "10  11        [2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4]   0.264258  0.173703   \n",
       "11  12     [2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4, 9]   0.263984  0.175880   \n",
       "12  13  [2, 8, 10, 3, 11, 7, 0, 5, 12, 1, 4, 9, 6]   0.252955  0.179987   \n",
       "\n",
       "    Test MSE  \n",
       "0   0.198382  \n",
       "1   0.201409  \n",
       "2   0.196570  \n",
       "3   0.195076  \n",
       "4   0.192623  \n",
       "5   0.185882  \n",
       "6   0.189306  \n",
       "7   0.189306  \n",
       "8   0.189270  \n",
       "9   0.190729  \n",
       "10  0.190242  \n",
       "11  0.189642  \n",
       "12  0.178748  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_list1 = []\n",
    "f1 = []\n",
    "for i in range(13):\n",
    "    f_list1.append(selected[i])\n",
    "    f1.append(np.array(f_list1))\n",
    "print(\"Feature Subsets (GFFS)\")\n",
    "pd.DataFrame({'d':[1,2,3,4,5,6,7,8,9,10,11,12,13],\n",
    "        'Feature Subset': f1,\n",
    "        'Train MSE': GFFS_MSE_train,\n",
    "        'Val MSE': GFFS_MSE_val,\n",
    "        'Test MSE': GFFS_MSE_test\n",
    "       } )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907b060",
   "metadata": {},
   "source": [
    "### Greedy backward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "98b3d3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers = 138\n",
      "13\n",
      "0.2513482443793425 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12]\n",
      "12\n",
      "0.25276859236808624 [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12]\n",
      "11\n",
      "0.25333810560318615 [1, 2, 4, 5, 6, 7, 8, 9, 10, 12]\n",
      "10\n",
      "0.2534245566121678 [1, 2, 4, 5, 6, 7, 8, 10, 12]\n",
      "9\n",
      "0.2541159812141366 [2, 4, 5, 6, 7, 8, 10, 12]\n",
      "8\n",
      "0.25491123634195373 [2, 5, 6, 7, 8, 10, 12]\n",
      "7\n",
      "0.25491123634195373 [2, 6, 7, 8, 10, 12]\n",
      "6\n",
      "0.25535110861241384 [2, 6, 7, 8, 12]\n",
      "5\n",
      "0.2559740883822686 [2, 6, 7, 8]\n",
      "4\n",
      "0.2690252529327015 [2, 7, 8]\n",
      "3\n",
      "0.31212093121358947 [2, 7]\n",
      "2\n",
      "0.3130606408758953 [2]\n",
      "[-1, 11, 3, 0, 9, 1, 4, 5, 10, 12, 6, 8, 7, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['sqft_living15', 'sqft_lot', 'bedrooms', 'sqft_above', 'bathrooms',\n",
       "       'floors', 'waterfront', 'sqft_basement', 'sqft_lot15', 'view',\n",
       "       'grade', 'condition', 'sqft_living'], dtype=object)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, xnum, xdr, ynum, ydr = preprocess(df, 0.75, missingValues=\"imputemean\")\n",
    "removed, GBFS_MSE_train, GBFS_MSE_val, GBFS_MSE_test = GBFS(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "print(removed)\n",
    "np.array(df.columns)[removed[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b823dca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>Feature Subset</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Val MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>0.248330</td>\n",
       "      <td>0.173249</td>\n",
       "      <td>0.160088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12]</td>\n",
       "      <td>0.251348</td>\n",
       "      <td>0.170032</td>\n",
       "      <td>0.163241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12]</td>\n",
       "      <td>0.252769</td>\n",
       "      <td>0.167387</td>\n",
       "      <td>0.162353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8, 9, 10, 12]</td>\n",
       "      <td>0.253338</td>\n",
       "      <td>0.165889</td>\n",
       "      <td>0.160448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8, 10, 12]</td>\n",
       "      <td>0.253425</td>\n",
       "      <td>0.164915</td>\n",
       "      <td>0.160748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>[2, 4, 5, 6, 7, 8, 10, 12]</td>\n",
       "      <td>0.254116</td>\n",
       "      <td>0.164097</td>\n",
       "      <td>0.162061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[2, 5, 6, 7, 8, 10, 12]</td>\n",
       "      <td>0.254911</td>\n",
       "      <td>0.163271</td>\n",
       "      <td>0.159668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>[2, 6, 7, 8, 10, 12]</td>\n",
       "      <td>0.254911</td>\n",
       "      <td>0.163271</td>\n",
       "      <td>0.159668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>[2, 6, 7, 8, 12]</td>\n",
       "      <td>0.255351</td>\n",
       "      <td>0.163369</td>\n",
       "      <td>0.162398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>[2, 6, 7, 8]</td>\n",
       "      <td>0.255974</td>\n",
       "      <td>0.166645</td>\n",
       "      <td>0.165264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 7, 8]</td>\n",
       "      <td>0.269025</td>\n",
       "      <td>0.173393</td>\n",
       "      <td>0.173692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>[2, 7]</td>\n",
       "      <td>0.312121</td>\n",
       "      <td>0.182335</td>\n",
       "      <td>0.179744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.313061</td>\n",
       "      <td>0.186647</td>\n",
       "      <td>0.181600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     d                              Feature Subset  Train MSE   Val MSE  \\\n",
       "0   13  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   0.248330  0.173249   \n",
       "1   12      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12]   0.251348  0.170032   \n",
       "2   11         [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12]   0.252769  0.167387   \n",
       "3   10            [1, 2, 4, 5, 6, 7, 8, 9, 10, 12]   0.253338  0.165889   \n",
       "4    9               [1, 2, 4, 5, 6, 7, 8, 10, 12]   0.253425  0.164915   \n",
       "5    8                  [2, 4, 5, 6, 7, 8, 10, 12]   0.254116  0.164097   \n",
       "6    7                     [2, 5, 6, 7, 8, 10, 12]   0.254911  0.163271   \n",
       "7    6                        [2, 6, 7, 8, 10, 12]   0.254911  0.163271   \n",
       "8    5                            [2, 6, 7, 8, 12]   0.255351  0.163369   \n",
       "9    4                                [2, 6, 7, 8]   0.255974  0.166645   \n",
       "10   3                                   [2, 7, 8]   0.269025  0.173393   \n",
       "11   2                                      [2, 7]   0.312121  0.182335   \n",
       "12   1                                         [2]   0.313061  0.186647   \n",
       "\n",
       "    Test MSE  \n",
       "0   0.160088  \n",
       "1   0.163241  \n",
       "2   0.162353  \n",
       "3   0.160448  \n",
       "4   0.160748  \n",
       "5   0.162061  \n",
       "6   0.159668  \n",
       "7   0.159668  \n",
       "8   0.162398  \n",
       "9   0.165264  \n",
       "10  0.173692  \n",
       "11  0.179744  \n",
       "12  0.181600  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_list = np.arange(0,13,1)\n",
    "f = []\n",
    "for i in range(1,14):\n",
    "    f.append(f_list)\n",
    "    f_list = f_list[f_list != removed[i]]\n",
    "pd.DataFrame({'d':[13,12,11,10,9,8,7,6,5,4,3,2,1],\n",
    "        'Feature Subset': f,\n",
    "        'Train MSE': GBFS_MSE_train,\n",
    "        'Val MSE': GBFS_MSE_val,\n",
    "        'Test MSE': GBFS_MSE_test\n",
    "       } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91858f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
